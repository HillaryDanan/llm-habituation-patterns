{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pilot Study Analysis\n",
    "\n",
    "## Quick analysis of pilot data to validate approach before full studies\n",
    "\n",
    "**Goals:**\n",
    "1. Verify metrics are calculating correctly\n",
    "2. Check for expected patterns (even with low N)\n",
    "3. Identify any methodological issues\n",
    "4. Estimate effect sizes for power analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = Path('../data/processed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Pilot Data\n",
    "\n",
    "Load the most recent pilot results from Study 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most recent pilot file\n",
    "pilot_files = sorted(DATA_DIR.glob('study1_results_*.csv'))\n",
    "\n",
    "if not pilot_files:\n",
    "    print(\"❌ No pilot data found. Run: python3 src/studies/study_1_habituation.py --pilot\")\n",
    "else:\n",
    "    df = pd.read_csv(pilot_files[-1])\n",
    "    print(f\"✅ Loaded: {pilot_files[-1].name}\")\n",
    "    print(f\"\\nShape: {df.shape}\")\n",
    "    print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "    df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary by condition and model\n",
    "summary = df.groupby(['model', 'condition'])[['entropy', 'mtld', 'token_count']].agg(['mean', 'std', 'count'])\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Key Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entropy by condition\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for idx, model in enumerate(df['model'].unique()):\n",
    "    model_df = df[df['model'] == model]\n",
    "    \n",
    "    sns.boxplot(data=model_df, x='condition', y='entropy', ax=axes[idx])\n",
    "    axes[idx].set_title(f'{model} - Entropy by Condition')\n",
    "    axes[idx].set_ylabel('Shannon Entropy (normalized)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/pilot_entropy_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Statistical Tests (Preliminary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent samples t-test for each model\n",
    "print(\"=\"*60)\n",
    "print(\"PRELIMINARY STATISTICAL TESTS (Pilot Data - Low Power)\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "for model in df['model'].unique():\n",
    "    model_df = df[df['model'] == model]\n",
    "    \n",
    "    rep = model_df[model_df['condition'] == 'repetitive']['entropy']\n",
    "    nov = model_df[model_df['condition'] == 'novel']['entropy']\n",
    "    \n",
    "    t_stat, p_value = stats.ttest_ind(rep, nov)\n",
    "    \n",
    "    # Cohen's d\n",
    "    pooled_std = np.sqrt((rep.var() + nov.var()) / 2)\n",
    "    cohens_d = (rep.mean() - nov.mean()) / pooled_std if pooled_std > 0 else 0\n",
    "    \n",
    "    print(f\"Model: {model}\")\n",
    "    print(f\"  Repetitive mean: {rep.mean():.4f}\")\n",
    "    print(f\"  Novel mean:      {nov.mean():.4f}\")\n",
    "    print(f\"  t-statistic:     {t_stat:.4f}\")\n",
    "    print(f\"  p-value:         {p_value:.4f} {'**' if p_value < 0.05 else ''}\")\n",
    "    print(f\"  Cohen's d:       {cohens_d:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Time Series: Entropy Over Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot entropy trajectory over trials\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for idx, model in enumerate(df['model'].unique()):\n",
    "    model_df = df[df['model'] == model]\n",
    "    \n",
    "    for condition in ['repetitive', 'novel']:\n",
    "        cond_df = model_df[model_df['condition'] == condition]\n",
    "        axes[idx].plot(cond_df['prompt_index'], cond_df['entropy'], \n",
    "                      marker='o', label=condition, alpha=0.7)\n",
    "    \n",
    "    axes[idx].set_xlabel('Trial Index')\n",
    "    axes[idx].set_ylabel('Entropy')\n",
    "    axes[idx].set_title(f'{model}')\n",
    "    axes[idx].legend()\n",
    "\n",
    "plt.suptitle('Entropy Trajectories Over Trials (Pilot)', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/pilot_entropy_trajectories.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Power Analysis for Full Study\n",
    "\n",
    "Estimate required N based on observed effect sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.power import TTestIndPower\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"POWER ANALYSIS FOR FULL STUDY\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "power_analysis = TTestIndPower()\n",
    "\n",
    "for model in df['model'].unique():\n",
    "    model_df = df[df['model'] == model]\n",
    "    \n",
    "    rep = model_df[model_df['condition'] == 'repetitive']['entropy']\n",
    "    nov = model_df[model_df['condition'] == 'novel']['entropy']\n",
    "    \n",
    "    pooled_std = np.sqrt((rep.var() + nov.var()) / 2)\n",
    "    observed_d = abs((rep.mean() - nov.mean()) / pooled_std) if pooled_std > 0 else 0\n",
    "    \n",
    "    # Calculate required N for power=0.80, alpha=0.05\n",
    "    if observed_d > 0:\n",
    "        required_n = power_analysis.solve_power(effect_size=observed_d, alpha=0.05, power=0.80)\n",
    "        print(f\"Model: {model}\")\n",
    "        print(f\"  Observed Cohen's d: {observed_d:.4f}\")\n",
    "        print(f\"  Required N per condition (power=0.80): {int(np.ceil(required_n))}\")\n",
    "        print(f\"  Planned N: 100\")\n",
    "        print(f\"  Status: {'✅ Adequate' if required_n <= 100 else '⚠️  Underpowered'}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Lexical Diversity (MTLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare MTLD across conditions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for idx, model in enumerate(df['model'].unique()):\n",
    "    model_df = df[df['model'] == model]\n",
    "    \n",
    "    sns.boxplot(data=model_df, x='condition', y='mtld', ax=axes[idx])\n",
    "    axes[idx].set_title(f'{model} - MTLD by Condition')\n",
    "    axes[idx].set_ylabel('MTLD Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/pilot_mtld_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusions from Pilot\n",
    "\n",
    "**Questions to address:**\n",
    "1. Do we see expected direction of effects (even if not significant)?\n",
    "2. Are metrics behaving as expected?\n",
    "3. Any methodological issues to fix?\n",
    "4. Is N=100 adequate for full study?\n",
    "\n",
    "**Next steps:**\n",
    "- Refine prompts if needed\n",
    "- Adjust N if power analysis suggests\n",
    "- Proceed to full Study 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save summary statistics\n",
    "summary.to_csv('../results/pilot_summary_statistics.csv')\n",
    "print(\"✅ Pilot analysis complete! Summary saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}